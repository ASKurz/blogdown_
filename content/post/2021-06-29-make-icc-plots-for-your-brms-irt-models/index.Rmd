---
title: Make ICC plots for your brms IRT models
author: A. Solomon Kurz
date: '2021-06-29'
slug: ''
categories: []
tags:
  - Bayesian
  - brms
  - IRT
  - multilevel
  - plot
  - R
  - tidyverse
  - tutorial
subtitle: ''
summary: ''
authors: []
lastmod: '2021-06-29T11:22:57-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
bibliography: /Users/solomonkurz/Dropbox/blogdown/content/post/my_blog.bib
biblio-style: apalike
csl: /Users/solomonkurz/Dropbox/blogdown/content/post/apa.csl  
link-citations: yes
---

```{r, echo = F, cache = F}
# knitr::opts_chunk$set(fig.retina = 2.5)
options(width = 110)
```

```{r, echo = F}
# save(irt1, file = "fits/irt1.rda")
# save(irt2, file = "fits/irt2.rda")

load("fits/irt1.rda")
load("fits/irt2.rda")
```

## Context

Someone recently posted a [thread on the Stan forums](https://discourse.mc-stan.org/t/item-characteristic-curves-and-item-information-curves-from-item-response-models/22964) asking how one might make item-characteristic curve (ICC) and item-information curve (IIC) plots for an item-response theory (IRT) model fit with **brms**. People were slow to provide answers and I came up disappointingly empty handed after a quick web search. The purpose of this blog post is to show how one might make ICC and IIC plots for **brms** IRT models using general-purpose data wrangling steps.

### I make assumptions.

This tutorial is for those with a passing familiarity with the following:

* You'll want to be familiar with the **brms** package [@R-brms; @burknerBrmsPackageBayesian2017; @burknerAdvancedBayesianMultilevel2018]. In addition to the references I just cited, you can find several helpful vignettes at [https://github.com/paul-buerkner/brms](https://github.com/paul-buerkner/brms). I've also written a few ebooks highlighting **brms**, which you can find at [https://solomonkurz.netlify.app/bookdown/](https://solomonkurz.netlify.app/bookdown/).

* You'll want to be familiar with Bayesian multilevel regression. In addition to the resources, above, I recommend either edition of McElreath's introductory text [-@mcelreathStatisticalRethinkingBayesian2015; -@mcelreathStatisticalRethinkingBayesian2020] or Kruschke's [-@kruschkeDoingBayesianData2015] introductory text.

* You'll want to be familiar with IRT. The framework in this blog comes most directly from B端rkner's [-@burknerBayesianItemResponse2020] preprint. Though I'm not in a position to vouch for them myself, I've had people recommend @crockerIntroductionToClassical2006; @deayalaTheoryAndPractice2008; @reckaseMultidimensionalIRT2009; @bonifayMultidimensionalIRT2019[^1]; and @albanoIntroductionToEducational2020.
 
* All code is in **R** [@R-base], with healthy doses of the **tidyverse** [@R-tidyverse; @wickhamWelcomeTidyverse2019]. Probably the best place to learn about the **tidyverse**-style of coding, as well as an introduction to **R**, is Grolemund and Wickham's [-@grolemundDataScience2017] freely-available online text, [*R for data science*](https://r4ds.had.co.nz).

Load the primary **R** packages.

```{r, warning = F, message = F}
library(tidyverse)
library(brms)
```

## Data

The data for this post come from the preprint by @loramValidationOfANovel2019, who generously shared their data and code on [GitHub](https://github.com/Lingtax/2018_measures_study) and the [Open Science Framework](https://osf.io/t9w2x/). In their paper, they used IRT to make a self-report measure of climate change denial. After pruning their initial item set, Loram and colleagues settled on eight binary items for their measure. Here we load the data for those items[^2].

```{r}
load("data/ccdrefined02.rda")

ccdrefined02 %>% 
  glimpse()
```

If you walk through the code in Loram and colleagues' [`2018_Loram_CC_IRT.R`](https://github.com/Lingtax/2018_measures_study/blob/master/Rcode/2018_Loram_CC_IRT.R) file, you'll see where this version of the data comes from. For our purposes, we'll want to make an explicit participant number column and then convert the data to the long format.

```{r}
dat_long <-
  ccdrefined02 %>% 
  mutate(id = 1:n()) %>% 
  pivot_longer(-id, names_to = "item", values_to = "y") %>% 
  mutate(item = str_remove(item, "ccd"))

# what did we do?
head(dat_long)
```

Now responses (`y`) are nested within participants (`id`) and items (`item`).

## IRT

In his -@burknerBayesianItemResponse2020 preprint, B端rkner outlined the framework for the multilevel Bayesian approach to IRT, as implemented in **brms**. In short, IRT allows one to decompose the information from assessment measures into person parameters $(\theta)$ and item parameters $(\xi)$. The IRT framework offers a large variety of model types. In this post, we'll focus on the widely-used 1PL and 2PL models. First, we'll briefly introduce them within the context of B端rkner's multilevel Bayesian approach. Then we'll fit those models to the `dat_long` data. Finally, we'll show how to explore those models using ICC and IIC plots.

### What is the 1PL?

With a set of binary data $y_{pi}$, which vary across $P$ persons and $I$ items, we can express the simple one-parameter logistic (1PL) model as

$$
\begin{align*}
y_{pi} & \sim \operatorname{Bernoulli}(p_{pi}) \\
\operatorname{logit}(p_{pi}) & = \theta_p + \xi_i,
\end{align*}
$$

where the $p_{pi}$ parameter from the Bernoulli distribution indicates the probability of `1` for the $p\text{th}$ person on the $i\text{th}$ item. To constrain the model predictions to within the $[0, 1]$ probability space, we use the logit link. Note that with this parameterization, the linear model itself is just the additive sum of the person parameter $\theta_p$ and item parameter $\xi_i$.

Within our multilevel Bayesian framework, we will expand this a bit to

$$
\begin{align*}
y_{pi} & \sim \operatorname{Bernoulli}(p_{pi}) \\
\operatorname{logit}(p_{pi}) & = \beta_0 + \theta_p + \xi_i \\
\theta_p & \sim \operatorname{Normal}(0, \sigma_\theta) \\
\xi_i    & \sim \operatorname{Normal}(0, \sigma_\xi),
\end{align*}
$$

where the new parameter $\beta_0$ is the grand mean. Now our $\theta_p$ and $\xi_i$ parameters are expressed as deviations around the grand mean $\beta_0$. As is typical within the multilevel framework, we model these deviations as normally distributed with means set to zero and standard deviations ($\sigma_\theta$ and $\sigma_\xi$) estimated from the data[^3].

To finish off our multilevel Bayesian version the 1PL, we just need to add in our priors. In this blog post, we'll follow the weakly-regularizing approach and set

$$
\begin{align*}
\beta_0 & \sim \operatorname{Normal}(0, 1.5) \\
\sigma_\theta & \sim \operatorname{Student-t}^+(10, 0, 1) \\
\sigma_\xi    & \sim \operatorname{Student-t}^+(10, 0, 1),
\end{align*}
$$

where the $+$ superscripts indicate the Student-$t$ priors for the $\sigma$ parameters are restricted to non-negative values.

### How about the 2PL?

We can express the two-parameter logistic (2PL) model as

$$
\begin{align*}
y_{pi} & \sim \operatorname{Bernoulli}(p_{pi}) \\
\operatorname{logit}(p_{pi}) & = \alpha_i \theta_p + \alpha_i \xi_i \\
                             & = \alpha_i(\theta_p + \xi_i),
\end{align*}
$$

where the $\theta_p$ and $\xi_i$ parameters are now both multiplied by the discrimination parameter $\alpha_i$. The $i$ subscript indicates the discrimination parameter varies across the items, but not across persons. We should note that because we are now multiplying parameters, this makes the 2PL a non-liner model. Within our multilevel Bayesian framework, we might express the 2PL as

$$
\begin{align*}
y_{pi} & \sim \operatorname{Bernoulli}(p_{pi}) \\
\operatorname{logit}(p_{pi}) & = \alpha (\beta_0 + \theta_p + \xi_i) \\
\alpha & = \beta_1 + \alpha_i \\
\theta_p & \sim \operatorname{Normal}(0, \sigma_\theta) \\
\begin{bmatrix} \alpha_i \\ \xi_i \end{bmatrix} & \sim \operatorname{MVNormal}(\mathbf 0, \mathbf \Sigma) \\
\Sigma    & = \mathbf{SRS} \\
\mathbf S & = \begin{bmatrix} \sigma_\alpha & 0 \\ 0 & \sigma_\xi \end{bmatrix} \\
\mathbf R & = \begin{bmatrix} 1 & \rho \\ \rho & 1 \end{bmatrix} ,
\end{align*}
$$

where the $\alpha$ term is multiplied by $\beta_0$, in addition to the $\theta_p$ and $\xi_i$ parameters. But note that $\alpha$ is itself a composite of its own grand mean $\beta_1$ and the item-level deviations around it, $\alpha_i$. Since both $\alpha$ and $\xi$ vary across items, they are modeled as multivariate normal, with a mean vector of zeros and variance/covariance matrix $\mathbf \Sigma$. As is typical with **brms**, we will decompose $\mathbf \Sigma$ into a diagonal matrix of standard deviations $(\mathbf S)$ and a correlation matrix $(\mathbf R)$.

As B端rkner [-@burknerBayesianItemResponse2020] discussed in Section 5, this particular model might have identification problems without strong priors. The issue is "a switch in the sign of $[\alpha]$ can be corrected for by a switch in the sign of $[(\beta_0 + \theta_p + \xi_i)]$ without a change in the overall likelihood." One solution, then, would be to constrain $\alpha$ to be positive. We can do that with

$$
\begin{align*}
y_{pi} & \sim \operatorname{Bernoulli}(p_{pi}) \\
\operatorname{logit}(p_{pi}) & = \color{#8b0000}{ \exp(\log \alpha) } \times (\beta_0 + \theta_p + \xi_i) \\
\color{#8b0000}{\log \alpha} & = \beta_1 + \alpha_i \\
\theta_p & \sim \operatorname{Normal}(0, \sigma_\theta) \\
\begin{bmatrix} \alpha_i \\ \xi_i \end{bmatrix} & \sim \operatorname{MVNormal}(\mathbf 0, \mathbf \Sigma) \\
\Sigma    & = \mathbf{SRS} \\
\mathbf S & = \begin{bmatrix} \sigma_\alpha & 0 \\ 0 & \sigma_\xi \end{bmatrix} \\
\mathbf R & = \begin{bmatrix} 1 & \rho \\ \rho & 1 \end{bmatrix},
\end{align*}
$$

wherein we are now modeling $\alpha$ on the log scale and then exponentiating $\log \alpha$ within the linear formula for $\operatorname{logit}(p_{pi})$. Continuing on with our weakly-regularizing approach, we will express our priors for this model as

$$
\begin{align*}
\beta_0 & \sim \operatorname{Normal}(0, 1.5) \\
\beta_1 & \sim \operatorname{Normal}(0, 1) \\
\sigma_\theta & \sim \operatorname{Student-t}^+(10, 0, 1) \\
\sigma_\alpha & \sim \operatorname{Student-t}^+(10, 0, 1) \\
\sigma_\xi    & \sim \operatorname{Student-t}^+(10, 0, 1) \\
\mathbf R & \sim \operatorname{LKJ}(2),
\end{align*}
$$

where "LKJ" is the Lewandowski, Kurowicka, and Joe prior for correlation matrices [@lewandowski2009generating]. With $\eta = 2$, the LKJ weakly regularizes the correlations away from extreme values[^4].

### Fire up **brms**.

With `brms::brm()`, we can fit our 1PL model with conventional multilevel syntax.

```{r, eval = F}
irt1 <- brm(
  data = dat_long,
  family = brmsfamily("bernoulli", "logit"),
  y ~ 1 + (1 | item) + (1 | id),
  prior = c(prior(normal(0, 1.5), class = Intercept),
            prior(student_t(10, 0, 1), class = sd)),
  cores = 4, seed = 1
)
```

Our non-linear 2PL model, however, will require the **brms** non-linear syntax [@B端rkner2021Non_linear]. Here we'll follow the same basic configuration B端rkner used in his [-@burknerBayesianItemResponse2020] IRT preprint.

```{r, eval = F}
irt2 <- brm(
  data = dat_long,
  family = brmsfamily("bernoulli", "logit"),
  bf(
    y ~ exp(logalpha) * eta,
    eta ~ 1 + (1 |i| item) + (1 | id),
    logalpha ~ 1 + (1 |i| item),
    nl = TRUE
  ),
  prior = c(prior(normal(0, 1.5), class = b, nlpar = eta),
            prior(normal(0, 1), class = b, nlpar = logalpha),
            prior(student_t(10, 0, 1), class = sd, nlpar = eta),
            prior(student_t(10, 0, 1), class = sd, nlpar = logalpha),
            prior(lkj(2), class = cor)),
  cores = 4, seed = 1,
  control = list(adapt_delta = .99)
)
```

Note that for `irt2`, we had to adjust the `adapt_delta` settings to stave off a few divergent transitions. Anyway, here are the parameter summaries for the models.

```{r}
print(irt1)
print(irt2)
```

With respect to the $\sigma$ parameters, both models suggest the loin's share of the variability in the responses was due to variation in the participants, as expressed by the relatively large $\sigma_\theta$ parameters, which are summarized in the `sd(eta_Intercept)` rows. Even so, the items still vary quite a bit with respect to $\xi$ and $\alpha$. In the next two sections, we'll get a better sense of that variation with plots.

### ICCs.

For IRT models of binary items, item-characteristic curves (ICCs) show the expected relation between one's underlying "ability" and the probability of scoring 1 on a given item. In our models, above, each participant in the data had a their underlying ability estimated by way of the $\theta_i$ parameters. However, what we want, here, is is to specify the relevant part of the parameter space for $\theta$ without reference to any given participant. Since the the 1PL and 2PL models are fit with the logit link, this will mean entertaining $\theta$ values ranging within an interval like $[-4, 4]$ or $[-6, 6]$. This range will define our $x$ axis. Since our $y$ axis has to do with probabilities, it will range from 0 to 1. The trick is knowing how to work with the posterior draws to compute the relevant probability values for their corresponding $\theta$ values.

We'll start with our 1PL model, `irt1`. First, we extract the posterior draws.

```{r, results = "hide"}
post <- posterior_samples(irt1)

# what is this?
glimpse(post)
```

I'm not showing the output for `glimpse(post)` because `post` is a $4{,}000 \times 218$ data frame and all that output is just too much for a blog post. Here's a more focused look at the primary columns of interest.

```{r}
post %>% 
  select(b_Intercept, starts_with("r_item")) %>% 
  glimpse()
```

For each of our 8 questionnaire items, we compute their conditional probability with the equation

$$p(y = 1) = \operatorname{logit}^{-1}(\beta_0 + \xi_i + \theta),$$

where $\operatorname{logit}^{-1}$ is the inverse logit function

$$\frac{\exp(x)}{1 + \exp(x)}.$$

With **brms**, we have access to the $\operatorname{logit}^{-1}$ function by way of the convenience function called `inv_logit_scaled()`. Before we put the `inv_logit_scaled()` function to use, we'll want to rearrange our `post` samples into the long format so that all the $\xi_i$ draws for each of the eight items are nested within a single column, which we'll call `xi`. We'll index which draw corresponds to which of the eight items with a nominal `item` column. And to make this all work within the context of 4,000 posterior draws, we'll also need to make an iteration index, which we'll call `iter`.

```{r}
post <- post %>% 
  select(b_Intercept, starts_with("r_item")) %>% 
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_item"), names_to = "item", values_to = "xi") %>% 
  mutate(item = str_extract(item, "\\d+")) 

# what is this?
head(post)
```

Now we're ready to compute our probabilities, conditional in different ability $(\theta)$ levels.

```{r, warning = F, message = F}
post <- post %>% 
  expand(nesting(iter, b_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + xi + theta)) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))

# what have we done?
head(post)
```

With those summaries in hand, it's trivial to make the ICC plot with good old **ggplot2** syntax.

```{r}
post %>% 
  ggplot(aes(x = theta, y = p, color = item, fill = item)) +
  geom_line() +
  scale_fill_viridis_d(option = "H") +
  scale_color_viridis_d(option = "H") +
  labs(title = "ICCs for the 1PL",
       subtitle = "Each curve is based on the posterior mean.", 
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  theme_classic()
```

Since each item had a relatively low response probability, you have to go pretty far into the right-hand side of the $\theta$ range before the curves start to approach the top of the $y$ axis.

To make the ICCs for the 2PL model, the data wrangling will require a couple more steps. First, we extract the posterior draws and take a quick look at the columns of interest.

```{r}
post <- posterior_samples(irt2) 

# what do we care about?
post %>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_item")) %>% 
  glimpse()
```

Now there are 16 `r_item__` columns, half of which correspond to the $\xi_i$ deviations and the other half of which correspond to the $\alpha_i$ deviations. In addition, we also have the `b_logalpha_Intercept` columns to content with. So this time, we'll follow up our `pivot_longer()` code with subsequent `mutate()` and `select()` steps, and complete the task with `pivot_wider()`.

```{r}
post <- post %>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_item")) %>% 
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_item")) %>% 
  mutate(item      = str_extract(name, "\\d+"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha")) %>% 
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value)

# what does this look like, now?
head(post)
```

With this configuration, it's only a little more complicated to compute the probability summaries.

```{r, warning = F, message = F}
post <- post %>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  # note the difference in the equation
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi))) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p))

# what have we done?
head(post)
```

And we plot.

```{r}
post %>% 
  ggplot(aes(x = theta, y = p, color = item, fill = item)) +
  geom_line() +
  scale_fill_viridis_d(option = "H") +
  scale_color_viridis_d(option = "H") +
  labs(title = "ICCs for the 2PL",
       subtitle = "Each curve is based on the posterior mean.", 
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) +
  theme_classic()
```

Looks like those $\alpha_i$ parameters made a big difference for the ICCs.

### IICs.

From a computational standpoint, item information curves (IICs) are a transformation of the ICCs. Recall that the $y$ axis for the ICC is $p$, the probability $y = 1$ for a given item. For the IIC plots, the $y$ axis shows information, which is a simple transformation of $p$, following the form

$$\text{information} = p(1 - p).$$

So here's how to use that equation and make the IIC plot for our 1PL model.

```{r, message = F}
# these wrangling steps are all the same as before
posterior_samples(irt1) %>% 
  select(b_Intercept, starts_with("r_item")) %>% 
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_item"), names_to = "item", values_to = "xi") %>% 
  mutate(item = str_extract(item, "\\d+")) %>% 
  expand(nesting(iter, b_Intercept, item, xi),
         theta = seq(from = -6, to = 6, length.out = 200)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + xi + theta)) %>% 
  
  # this part, right here, is what's new
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, item) %>% 
  summarise(i = median(i)) %>%
  
  # now plot!
  ggplot(aes(x = theta, y = i, color = item, fill = item)) +
  geom_line() +
  scale_fill_viridis_d(option = "H") +
  scale_color_viridis_d(option = "H") +
  labs(title = "IICs for the 1PL",
       subtitle = "Each curve is based on the posterior median.", 
       x = expression(theta~('ability on the logit scale')),
       y = "information") +
  theme_classic()
```

For kicks and giggles, we used the posterior medians, rather than the means. It's similarly easy to compute the item-level information for the 2PL.

```{r, message = F}
# these wrangling steps are all the same as before
posterior_samples(irt2) %>% 
  select(b_eta_Intercept, b_logalpha_Intercept, starts_with("r_item")) %>% 
  mutate(iter = 1:n()) %>% 
  pivot_longer(starts_with("r_item")) %>% 
  mutate(item      = str_extract(name, "\\d+"),
         parameter = ifelse(str_detect(name, "eta"), "xi", "logalpha")) %>% 
  select(-name) %>% 
  pivot_wider(names_from = parameter, values_from = value) %>% 
  expand(nesting(iter, b_eta_Intercept, b_logalpha_Intercept, item, xi, logalpha),
         theta = seq(from = -6, to = 6, length.out = 200)) %>% 
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + logalpha) * (b_eta_Intercept + theta + xi))) %>% 

  # again, here's the new part
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, item) %>% 
  summarise(i = median(i)) %>%
  
  # now plot!
  ggplot(aes(x = theta, y = i, color = item, fill = item)) +
  geom_line() +
  scale_fill_viridis_d(option = "H") +
  scale_color_viridis_d(option = "H") +
  labs(title = "IICs for the 2PL",
       subtitle = "Each curve is based on the posterior median.", 
       x = expression(theta~('ability on the logit scale')),
       y = "information") +
  theme_classic()
```

## Overview

We might outlines the steps in this post as:

* Fit your **brms** IRT model.
* Inspect the model with all your standard quality checks (e.g., $\widehat R$ values, trace plots).
* Extract your posterior draws with the `posterior_samples()` function.
* Isolate the item-related columns. Within the multilevel IRT context, this will typically involve an overall intercept (e.g., `b_Intercept` for our 1PL `irt1`) and item-specific deviations (e.g., the columns starting with `r_item` in our 1PL `irt1`). 
* Arrange the data into a format that makes it easy to add the overall intercept in question to each of the item-level deviations in question. For me, this seemed easiest with the long format via the `pivot_longer()` function.
* Expand the data over a range of ability $(\theta)$ values. For me, this worked well with the `expand()` function.
* Use the model-implied formula to compute the $p(y = 1)$.
* Group the results by item and $\theta$ and summarize the $p(y = 1)$ distributions with something like the mean or median.
* Plot the results with `ggplot2::geom_line()` and friends.

## Next steps

You should be able to generalize this workflow to IRT models for data with more than two categories. You'll just have to be careful about juggling your thresholds. You might find some inspiration along these lines [here](https://bookdown.org/content/4857/monsters-and-mixtures.html#ordered-categorical-outcomes) and [here](https://bookdown.org/content/3686/ordinal-predicted-variable.html).

You could totally switch up this workflow to use some of the data wrangling helpers from the [**tidybayes** package](https://CRAN.R-project.org/package=tidybayes) [@R-tidybayes]. That could be a nifty little blog post in and of itself.

One thing that's super lame about conventional ICC/IIC plots is there's no expression of uncertainty. To overcome that, you could compute the 95% intervals (or 50% or whatever) in the same `summarise()` where you computed the mean and then express those interval bounds with something like `geom_ribbon()` in your plot. The difficulty I foresee is will result in overplotting for any models with more than like five items. Perhaps faceting would be the solution, there.

I'm no IRT jock and may have goofed some of the steps or equations. To report mistakes or provide any other constructive criticism, just chime in on this Twitter thread:

```{r echo = FALSE}
blogdown::shortcode('tweet', '1409951540228628482')
```

## Session info

```{r}
sessionInfo()
```

## References

[^1]: I should disclose that although I have not read through Bonifay's [-@bonifayMultidimensionalIRT2019] text, he offered to send me a copy around the time I uploaded this post.

[^2]: You can find a copy of these data on my GitHub [here](https://github.com/ASKurz/blogdown/tree/main/content/post/2021-06-29-make-icc-plots-for-your-brms-irt-models/data).

[^3]: Adopting the three-term multilevel structure--$\beta_0 + \theta_p + \xi_i$, where the latter two terms are $\operatorname{Normal}(0, \sigma_x)$--places this form of the 1PL model squarely within the generalized linear multilevel model (GLMM). McElreath [-@mcelreathStatisticalRethinkingBayesian2015, Chapter 12] referred to this particular model type as a cross-classified model. Coming from another perspective, Kruschke [-@kruschkeDoingBayesianData2015, Chapters 19 and 20] described this as a kind of multilevel analysis of variance (ANOVA).

[^4]: For a nice blog post on the LKJ, check out Stephen Martin's [*Is the LKJ(1) prior uniform? "Yes"*](http://srmart.in/is-the-lkj1-prior-uniform-yes/).

