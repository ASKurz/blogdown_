---
title: "Don't forget your inits"
author: "A. Solomon Kurz"
date: '2021-06-05'
slug: ''
categories: []
tags:
- Bayesian
- brms
- multilevel
- R
- starting values
- tidyverse
- tutorial
subtitle: ''
summary: ''
authors: []
lastmod: '2021-06-05T10:04:58-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
bibliography: /Users/solomonkurz/Dropbox/blogdown/content/post/my_blog.bib
biblio-style: apalike
csl: /Users/solomonkurz/Dropbox/blogdown/content/post/apa.csl
link-citations: yes
---

```{r, echo = F, cache = F}
# knitr::opts_chunk$set(fig.retina = 2.5)
options(width = 110)
```

```{r, echo = F}
# save(fit1, file = "fits/fit1.rda")
# save(fit2, file = "fits/fit2.rda")
# save(fit3, file = "fits/fit3.rda")

load("fits/fit1.rda")
load("fits/fit2.rda")
load("fits/fit3.rda")
```

## tl;dr

When your MCMC chains look a mess, you might have to manually set your initial values. If you're a fancy pants, you can use a custom function.

## Context

A collaborator asked me to help model some reaction-time data. One of the first steps was to decide on a reasonable likelihood function. You can see a productive Twitter thread on that process [here](https://twitter.com/SolomonKurz/status/1398000353875005444). Although I've settled on the shifted-lognormal function, I also considered the exponentially modified Gaussian function (a.k.a. exGaussian). As it turns out, the exGaussian can be fussy to work with! After several frustrating attempts, I solved the problem by fiddling with my initial values. The purpose of this post is to highlight the issue and give you some options.

### I make assumptions.

* This post is for Bayesians. For thorough introductions to contemporary Bayesian regression, I recommend either edition of McElreath's text [-@mcelreathStatisticalRethinkingBayesian2015; -@mcelreathStatisticalRethinkingBayesian2020]; Kruschke's [-@kruschkeDoingBayesianData2015] text; or Gelman, Hill, and Vehtari's [-@gelmanRegressionOtherStories2020] text.
* Though not necessary, it will help if you're familiar with multilevel regression. The texts by McElreath and Kruschke, from above, can both help with that.
* All code is in **R** [@R-base], with an emphasis on the [**brms** package](https://github.com/paul-buerkner/brms) [@R-brms; @burknerBrmsPackageBayesian2017; @burknerAdvancedBayesianMultilevel2018]. We will also make good use of the **tidyverse** [@R-tidyverse; @wickhamWelcomeTidyverse2019], the **patchwork** package [@R-patchwork], and **ggmcmc** [@R-ggmcmc; @marinGgmcmcAnalysisMCMC2016]. We will also use the **lisa** package [@R-lisa] to select the color palette for our figures.
 
Load the primary **R** packages and adjust the global plotting theme defaults.

```{r, warning = F, message = F}
# load
library(tidyverse)
library(brms)
library(patchwork)
library(ggmcmc)
library(lisa)

# define the color palette
fk <- lisa_palette("FridaKahlo", n = 31, type = "continuous")

# adjust the global plotting theme
theme_set(
  theme_gray(base_size = 13) +
    theme(
      text = element_text(family = "Times", color = fk[1]),
      axis.text = element_text(family = "Times", color = fk[1]),
      axis.ticks = element_line(color = fk[1]),
      legend.background = element_blank(),
      legend.box.background = element_blank(),
      legend.key = element_blank(),
      panel.background = element_rect(fill = alpha(fk[16], 1/4), color = "transparent"),
      panel.grid = element_blank(),
      plot.background = element_rect(fill = alpha(fk[16], 1/4), color = "transparent")
    )
)
```

The color palette in this post is inspired by [Frida Kahlo](https://en.wikipedia.org/wiki/Frida_Kahlo)'s [*Self-Portrait with Thorn Necklace and Hummingbird*](https://en.wikipedia.org/wiki/Self-Portrait_with_Thorn_Necklace_and_Hummingbird).

## We need data

I'm not at liberty to share the original data. However, I have simulated a new data set that has the essential features of the original and I have saved the file on GitHub. You can load it like this.

```{r}
load(url("https://github.com/ASKurz/blogdown/raw/main/content/post/2021-06-05-don-t-forget-your-inits/data/dat.rda?raw=true"))

# what is this?
glimpse(dat)
```

Our primary variable of interest is `rt`, which is simulated reaction times in milliseconds. The reaction times are nested within 26 participants, who are denoted by the `id` column. The data are not balanced.

```{r}
dat %>% 
  count(id, name = "trials") %>% 
  count(trials)
```

Whereas most participants have 1,280 trials, their numbers range from 320 to 2,560, which means we'll want a multilevel model.

## We can describe the data with the exGaussian function

To start getting a sense of the `rt` data, we'll make a density plot of the overall distribution.

```{r, fig.width = 6, fig.height = 3}
dat %>% 
  ggplot(aes(x = rt)) +
  geom_density(fill = fk[3], color = fk[3])
```

As is typical of reaction times, the data are continuous, non-negative, and strongly skewed to the right. There are any number of likelihood functions one can use to model data of this kind. One popular choice is the exGaussian. The exGaussian distribution has three parameters: $\mu$, $\sigma$, and $\beta$[^1]. The $\mu$ and $\sigma$ parameters govern the mean and standard deviation for the central Gaussian portion of the distribution. The $\beta$ parameter governs the rate of the exponential distribution, which is tacked on to the right-hand side of the distribution. Within **R**, you can compute the density of various exGaussian distributions using the `brms::dexgaussian()` function. If you fool around with the parameter settings, a bit, you can make an exGaussian curve that fits pretty closely to the shape of our `rt` data. For example, here's what it looks like when we set `mu = 1300`, `sigma = 150`, and `beta = 520`.

```{r, fig.width = 6, fig.height = 3}
tibble(rt = seq(from = 0, to = 5500, length.out = 300),
       d = dexgaussian(rt, mu = 1300, sigma = 150, beta = 520)) %>% 
  
  ggplot(aes(x = rt)) +
  geom_density(data = dat,
               fill = fk[3], color = fk[3]) +
  geom_line(aes(y = d), 
            color = fk[31], size = 5/4) +
  # zoom in on the bulk of the values
  coord_cartesian(xlim = c(0, 5000))
```

The fit isn't perfect, but it gives a sense of where things are headed. It's time to talk about modeling.

## Models

In this post, we will explore three options for modeling the reaction-time data. The first will use default options. The second option will employ manually-set starting points. For the third option, we will use pseudorandom number generators to define the starting points, all within a custom function.

### Model 1: Use the exGaussian with default settings.

When using **brms**, you can fit an exGaussian model by setting `family = exgaussian()`. Here we'll allow the $\mu$ parameters to vary by participant, but keep the $\sigma$ and $\beta$ parameters fixed.

```{r, eval = F, echo = F}
# 36.23781 mins

# There were 604 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See
# http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceededThere were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See
# http://mc-stan.org/misc/warnings.html#bfmi-lowExamine the pairs() plot to diagnose sampling problems
# The largest R-hat is 2.85, indicating chains have not mixed.
# Running the chains for more iterations may help. See
# http://mc-stan.org/misc/warnings.html#r-hatBulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
# Running the chains for more iterations may help. See
# http://mc-stan.org/misc/warnings.html#bulk-essTail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
# Running the chains for more iterations may help. See
# http://mc-stan.org/misc/warnings.html#tail-ess
```

```{r, eval = F}
fit1 <- brm(
  data = dat,
  family = exgaussian(),
  formula = rt ~ 1 + (1 | id),
  cores = 4, seed = 1
)
```

I'm not going to show them all, here, for the sake of space, but this model returned warnings about 604 transitions, 1 chain for which the estimated Bayesian Fraction of Missing Information was low, a large R-hat value of 2.85, and low bulk and tail effective sample sizes. In other words, this was a disaster. To help bring these all into focus, we'll want to take a look at the chains in a trace plot. Since we'll be doing this a few times, let's go ahead and make a custom trace plot geom to suit our purposes. We'll call it `geom_trace()`.

```{r}
geom_trace <- function(subtitle = NULL, 
                       xlab = "iteration", 
                       xbreaks = 0:4 * 500) {
  
  list(
    annotate(geom = "rect", 
             xmin = 0, xmax = 1000, ymin = -Inf, ymax = Inf,
             fill = fk[16], alpha = 1/2, size = 0),
    geom_line(size = 1/3),
    scale_color_manual(values = fk[c(3, 8, 27, 31)]),
    scale_x_continuous(xlab, breaks = xbreaks, expand = c(0, 0)),
    labs(subtitle = subtitle),
    theme(panel.grid = element_blank())
  )
  
}
```

For your real-world models, it's good to look at the tract plots for all major model parameters. Here we'll just focus on the $\mu$ intercept.

```{r, fig.width = 6, fig.height = 2.25, warning = F}
p1 <- ggs(fit1, burnin = TRUE) %>%
  filter(Parameter == "b_Intercept") %>% 
  mutate(chain = factor(Chain),
         intercept = value) %>% 
  
  ggplot(aes(x = Iteration, y = intercept, color = chain)) +
  geom_trace(subtitle = "fit1 (default settings)") +
  scale_y_continuous(breaks = c(0, 650, 1300), limits = c(NA, 1430))

p1
```

Since we pulled the chains using the `ggmcmc::ggs()` function, we were able to plot the warmup iterations (darker beige background on the left) along with the post-warmup iterations (lighter beige background on the right). Although one of our chains eventually made its way to the posterior, three out of the four stagnated near their starting values. This brings us to a major point in this post: *Starting points can be a big deal*.

### Starting points can be a big deal.

I'm not going to go into the theory underlying Markov chain Monte Carlo (MCMC) methods in any detail. For that, check out some of the latter chapters in @gillBayesianMethods2015 or @gelman2013bayesian. In brief, if you run a Markov chain for an infinite number of iterations, it will converge on the correct posterior distribution. The problem is we can't run our chains for that long, which means we have to be careful about whether our finite-length chains have converged properly. Starting points are one of the factors that can influence this process.

One of the ways to help make sure your MCMC chains are sampling well is to run multiple chains for a while and check to see whether they have all converged around the same parameter space. Ideally, each chain will start from a different initial value. In practice, the first several iterations following the starting values are typically discarded. With older methods, like the Gibbs sampler, this was called the "burn-in" period. With Hamiltonian Monte Carlo (HMC), which is what **brms** uses, we have a similar period called "warmup." When everything goes well, the MCMC chains will all have traversed from their starting values to sampling probabilistically from the posterior distribution once they have emerged from the warmup phase. However, this isn't always the case. Sometimes the chains get stuck around their stating values and continue to linger there, even after you have terminated the warmup period. When this happens, you'll end up with samples that are still tainted by their starting values and are not yet representative of the posterior distribution.

In our example, above, we used the **brms** default settings of four chains, each of which ran for 1,000 warmup iterations and then 1,000 post-warmup iterations. We also used the **brms** default for the starting values. These defaults are based on the Stan defaults, which is to randomly select the starting points from a uniform distribution ranging from -2 to 2. For details, see the [*Random initial values*](https://mc-stan.org/docs/2_25/reference-manual/initialization.html#random-initial-values) section of the *Stan Reference Manual* [@standevelopmentteamStanReferenceManual2021].

In my experience, the **brms** defaults are usually pretty good. My models often quickly traverse from their starting values to concentrate in the posterior, just like our second chain did, above. When things go wrong, sometimes adding stronger priors can work. Other times it makes sense to rescale or reparameterize the model, somehow. In this case, I have reasons to want to (a) use default priors and to (b) stick to the default parameterization applied to the transformed data. Happily, we have another trick at out disposal: We can adjust the starting points.

Within `brms::brm()`, we can control the starting values with the `inits` argument. The default is `inits = "random"`, which follows the Stan convention of sampling from $(-2, 2)$, as discussed above. Another option is to fix all starting values to zero by setting `inits = "0"`. This often works surprisingly well, but it wasn't the solution in this case. If you look at the trace plot, above, you'll see that all the starting values are a long ways from the target range, which is somewhere around 1,300. So why not just put the starting values near there?

### Model 2: Fit the model with initial values set by hand.

When you specify start values for the parameters in your Stan models, you need to do so with a list of lists. Each MCMC chain will need its own list. In our case, that means we'll need four separate lists, each of which will be nested within a single higher-order list. For example, here we'll define a single list called `inits`, which will have starting values defined for our primary three population-level parameters.

```{r}
inits <- list(
  Intercept = 1300,
  sigma     = 150,
  beta      = 520
  )

# what is this?
inits
```

Notice that we didn't bother setting a starting value for the standard-deviation parameter for the random intercepts. That parameter, then, will just get the **brms** default. The others will the the start values, as assigned. Now, since we have four chains to assign start values to, a quick and dirty method is to just use the same ones for all four chains. Here's how to do that.

```{r}
list_of_inits <- list(inits, inits, inits, inits)
```

Our `list_of_inits` object is a list into which we have saved four copies of our `inits` list. Here's how to use those values within `brms::brm()`. Just plug them into the `inits` argument.

```{r, eval = F, echo = F}
# 7.224334 mins
```

```{r, eval = F}
fit2 <- brm(
  data = dat,
  family = exgaussian(),
  formula = rt ~ 1 + (1 | id),
  cores = 4, seed = 1,
  inits = list_of_inits
)
```

The effective sample sizes are still a little low, but the major pathologies are now gone. Compare the updated traceplot for the intercept to the first one.

```{r, fig.width = 6, fig.height = 4.5, warning = F, message = F}
# adjust fit1
p1 <- p1 +
  geom_trace(subtitle = "fit1 (default settings)",
             xlab = NULL, xbreaks = NULL)

# fit2
p2 <- ggs(fit2) %>%
  filter(Parameter == "b_Intercept") %>% 
  mutate(chain = factor(Chain),
         intercept = value) %>% 
  
  ggplot(aes(x = Iteration, y = intercept, color = chain)) +
  geom_trace(subtitle = "fit2 (manual copy/paste inits settings)") +
  coord_cartesian(ylim = c(1200, 1400))

# combine
p1 / p2
```

Man that looks better! See how all four of our chains started out at 1,300? That's because of how we copy/pasted `inits` four times within our `list_of_inits` object. This is kinda okay, but we can do better.

### Model 3: Set the initial values with a custom function.

Returning back to MCMC theory, a bit, it's generally a better idea to assign each chain its own starting value. Then, if all chains converge into the same part in the parameter space, that provides more convincing evidence they're all properly exploring the posterior. To be clear, this isn't rigorous evidence. It's just better evidence than if we started them all in the same spot.

One way to give each chain its own starting value would be to manually set them. Here's what that would look like if we were only working with two chains.

```{r, eval = F}
# set the values for the first chain
inits1 <- list(
  Intercept = 1250,
  sigma     = 140,
  beta      = 500
  )

# set new values for the second chain
inits2 <- list(
  Intercept = 1350,
  sigma     = 160,
  beta      = 540
  )

# combine the two lists into a single list
list_of_inits <- list(inits1, inits2)
```

This approach will work fine, but it's tedious, especially if you'd like to apply it to a large number of parameters. A more programmatic approach would be to use a pseudorandom number-generating function to randomly set the starting values. Since the intercept is an unbounded parameter, the posterior for which will often look Gaussian, the `rnorm()` function can be a great choice for selecting its starting values. Since both $\sigma$ and $\beta$ parameters need to be non-negative, a better choice might be the `runif()` or `rgamma()` functions. Here we'll just use `runif()` for each.

Since we're talking about using the pseudorandom number generators to pick our values, it would be nice if the results were reproducible. We can do that by working in the `set.seed()` function. Finally, it would be really sweet if we had a way to wrap `set.seed()` and the various number-generating functions into a single higher-order function. Here's one way to make such a function, which I'm calling `set_inits()`.

```{r}
set_inits <- function(seed = 1) {
  
  set.seed(seed)
  list(
    Intercept = rnorm(n = 1, mean = 1300, sd = 100),
    sigma     = runif(n = 1, min = 100, max = 200),
    beta      = runif(n = 1, min = 450, max = 550)
  )
  
}

# try it out
set_inits(seed = 0)
```

Notice how we set the parameters within the `rnorm()` and `runif()` functions to values that seemed reasonable given our model. These values aren't magic and you could adjust them to your own needs. Now, here's how to use our handy `set_inits()` function to choose similar, but distinct, starting values for each of our four chains. We save the results in a higher-order list called `my_second_list_of_inits`.

```{r}
my_second_list_of_inits <- list(
  # different seed values will return different results
  set_inits(seed = 1),
  set_inits(seed = 2),
  set_inits(seed = 3),
  set_inits(seed = 4)
)

# what have we done?
str(my_second_list_of_inits)
```

Now just plug `my_second_list_of_inits` into the `inits` argument and fit the model.

```{r, eval = F, echo = F}
# 7.400667 mins
```

```{r, eval = F}
fit3 <- brm(
  data = dat,
  family = exgaussian(),
  formula = rt ~ 1 + (1 | id),
  cores = 4, seed = 1,
  inits = my_second_list_of_inits
)
```

As with `fit2`, our `fit3` came out okay. Let's inspect the intercept parameter with a final trace plot.

```{r, fig.width = 6, fig.height = 6.75, warning = F, message = F}
# adjust fit2
p2 <- p2 +
  geom_trace(subtitle = "fit2 (manual copy/paste inits settings)",
             xlab = NULL, xbreaks = NULL)

# fit3
p3 <- ggs(fit3) %>%
  filter(Parameter == "b_Intercept") %>% 
  mutate(chain = factor(Chain),
         intercept = value) %>% 
  
  ggplot(aes(x = Iteration, y = intercept, color = chain)) +
  geom_trace(subtitle = "fit3 (inits by a custom function)") +
  coord_cartesian(ylim = c(1200, 1400))

# combine
p1 / p2 / p3
```

Now we have visual evidence that even though all four chains started at different places in the parameter space, they all converged into the same area. This still isn't fully rigorous evidence our chains are performing properly, but it's a major improvement from `fit1` and a minor improvement from `fit2`. They aren't shown here, but the same point holds for the $\sigma$ and $\beta$ parameters.

Okay, just for kicks and giggles, let's see how well our last model did by way of a posterior predictive check.

```{r, fig.width = 6, fig.height = 3, message = F}
bayesplot::color_scheme_set(fk[c(31, 31, 31, 3, 3, 3)])

pp_check(fit3, nsamples = 100) + 
  # we don't need to see the whole right tail
  coord_cartesian(xlim = c(0, 5000))
```

The model could be better, but it's moving in the right direction and there don't appear to be any major pathologies, like what we saw with `fit1`.

## Recap

* If your try to fit a model with MCMC, you may sometimes end up with pathologies, such as divergent transitions, large numbers of transitions, high R-hat values, and/or very low effective sample size estimates. 
* Sometimes these pathologies arise when the starting values for your chains are far away from the centers of their posterior densities.
* When using **brms**, you can solve this problem by setting the starting values with the `inits` argument.
* One approach is to manually set the starting values, saving them in a list of lists.
* Another approach is to use the pseudorandom number generators, such as `rnorm()` and `runif()`, to assign starting values within user-defined ranges.

## Session info

```{r}
sessionInfo()
```

## References

[^1]: There are different ways to parameterize the exGaussian distribution and these differences may involve different ways to express what we're calling $\beta$. Since our parameterization is based on Paul Bürkner's work, you might check out the [*Response time models*](https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html#response-time-models) section in his [-@Bürkner2021Parameterization] document, *Parameterization of response distributions in brms*.

