---
title: Yes, you can fit an exploratory factor analysis with lavaan
author: A. Solomon Kurz
date: '2021-05-11'
slug: ''
categories: []
tags:
  - EFA
  - lavaan
  - R
  - tutorial
subtitle: ''
summary: ''
authors: []
lastmod: '2021-05-11T09:35:30-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
bibliography: /Users/solomonkurz/Dropbox/blogdown/content/post/my_blog.bib
biblio-style: apalike
csl: /Users/solomonkurz/Dropbox/blogdown/content/post/apa.csl  
link-citations: yes
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="purpose" class="section level2">
<h2>Purpose</h2>
<p>Just this past week, I learned that, <em>Yes</em>, you can fit an exploratory factor analysis (EFA) with <strong>lavaan</strong> <span class="citation">(<a href="#ref-rosseellavaan2012" role="doc-biblioref">Rosseel, 2012</a>; <a href="#ref-R-lavaan" role="doc-biblioref">Rosseel &amp; Jorgensen, 2019</a>)</span>. At the moment, this functionality is only unofficially supported, which is likely why many don’t know about it, yet. You can get the [un]official details at <a href="https://github.com/yrosseel/lavaan/issues/112">issue #112</a> on the <strong>lavaan</strong> GitHub repository (<a href="https://github.com/yrosseel/lavaan">https://github.com/yrosseel/lavaan</a>). The purpose of this blog post is to make EFAs with <strong>lavaan</strong> even more accessible and web searchable by walking through a quick example.</p>
</div>
<div id="set-up" class="section level2">
<h2>Set up</h2>
<p>First, load our focal package, <strong>lavaan</strong>, along with the <strong>tidyverse</strong>.</p>
<pre class="r"><code>library(tidyverse)
library(lavaan)</code></pre>
<p>The data are a subset of the data from <span class="citation"><a href="#ref-arrudaPsychometricProperties2020" role="doc-biblioref">Arruda et al.</a> (<a href="#ref-arrudaPsychometricProperties2020" role="doc-biblioref">2020</a>)</span>. You can find various supporting materials for their paper on the <a href="https://osf.io">OSF</a> at <a href="https://osf.io/kx2ym/">https://osf.io/kx2ym/</a>. We will load a subset of the data saved in their <code>Base R - EFICA (manuscript and book chapter).RData</code> file (available at <a href="https://osf.io/p3fs6/">https://osf.io/p3fs6/</a>) called <code>ds</code>.</p>
<pre class="r"><code>load(&quot;data/ds.rda&quot;)

# what is this?
dim(ds)</code></pre>
<pre><code>## [1] 3284  540</code></pre>
<p>Here we extract a subset of the columns, rename them, and save the reduced data frame as <code>d</code>.</p>
<pre class="r"><code>d &lt;-
  ds %&gt;% 
  select(ife_1:ife_65) %&gt;% 
  set_names(str_c(&quot;y&quot;, 1:65))</code></pre>
<p>Participants were <span class="math inline">\(N = 3{,}284\)</span> parents of children or adolescents, in Brazil. The columns in our <code>d</code> data are responses to 65 items from the parent version of an “assessment tool developed to comprehensively assess dysfunctional behaviors related to” executive functioning, called the Executive function inventory for children and adolescents (EFICA; p. 5). On each item, the parents rated their kids on a 3-point Likert-type scale ranging from 0 (<em>never</em>) to 2 (<em>always/almost always</em>). To give a better sense of the items:</p>
<blockquote>
<p>The Parents’ version (EFICA-P) encompassed behaviors especially performed at home, such as “Leaves the light on, door open or wet towels on top of the bed, even after being told several times,” “Explodes or gets angry when he/she is contradicted” and/or “Interrupts others, doesn’t know how to wait for his/her turn to talk.” (p. 5)</p>
</blockquote>
<p>We won’t be diving into the substance of the paper, here. For that, see <span class="citation"><a href="#ref-arrudaPsychometricProperties2020" role="doc-biblioref">Arruda et al.</a> (<a href="#ref-arrudaPsychometricProperties2020" role="doc-biblioref">2020</a>)</span>. But for data validation purposes, the items should only take on integers 0 through 2. Turns out that the data did contain a few coding errors, which we will convert to missing data, here.</p>
<pre class="r"><code>d &lt;-
  d %&gt;% 
  mutate_at(vars(y1:y65), ~ifelse(. %in% c(0:2), ., NA))</code></pre>
<p>Here are the overall distributions, collapsing across items.</p>
<pre class="r"><code>d %&gt;% 
  pivot_longer(everything()) %&gt;% 
  count(value) %&gt;% 
  mutate(percent = (100 * n / sum(n)) %&gt;% round(digits = 1))</code></pre>
<pre><code>## # A tibble: 4 x 3
##   value     n percent
##   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1     0 85480    40  
## 2     1 94490    44.3
## 3     2 32276    15.1
## 4    NA  1214     0.6</code></pre>
<p>We might make a tile plot to get a sense high-level sense of the distributions across the items.</p>
<pre class="r"><code>d %&gt;% 
  pivot_longer(everything()) %&gt;% 
  mutate(item = factor(name, 
                       levels = str_c(&quot;y&quot;, 1:65),
                       labels = 1:65)) %&gt;% 
  count(item, value) %&gt;% 
  
  ggplot(aes(x = value, y = item, fill = n)) +
  geom_tile() +
  scale_fill_viridis_c(expression(italic(n)), limits = c(0, NA)) +
  scale_x_continuous(&quot;Likert rating&quot;, expand = c(0, 0), breaks = 0:2) +
  ggtitle(&quot;EFICA-P items&quot;) +
  theme(axis.text.x = element_text(size = 6))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-8-1.png" width="336" /></p>
</div>
<div id="efa-in-lavaan" class="section level2">
<h2>EFA in <strong>lavaan</strong></h2>
<div id="consider-your-estimation-method." class="section level3">
<h3>Consider your estimation method.</h3>
<p>An important preliminary step before fitting an EFA is getting a good sense of the data. In the last section, we learned the data are composed of three ordinal categories, which means that conventional estimators, such as maximum likelihood, won’t be the best of choices. Happily, <strong>lavaan</strong> offers several good options for ordinal data, which you can learn more about at <a href="https://lavaan.ugent.be/tutorial/cat.html">https://lavaan.ugent.be/tutorial/cat.html</a> and <a href="https://lavaan.ugent.be/tutorial/est.html">https://lavaan.ugent.be/tutorial/est.html</a>. The default is the WLSMV estimator (i.e., <code>estimator = "WLSMV"</code>), which our friends in quantitative methodology have shown is generally a good choice <span class="citation">(e.g., <a href="#ref-flora2004empirical" role="doc-biblioref">Flora &amp; Curran, 2004</a>; <a href="#ref-liCFAWithOrdinalData2016" role="doc-biblioref">Li, 2016</a>)</span>.</p>
</div>
<div id="how-many-factors-should-we-consider" class="section level3">
<h3>How many factors should we consider?</h3>
<p>In the paper, Arruda and colleagues considered models with up to five factors. Here we’re going to keep things simple and consider between one and three. However, I’d be remiss not to mention that for real-world analyses, this step is important and possibly underappreciated. Decades of methodological work suggest that some of the widely-used heuristics for deciding on the number of factors (e.g., scree plots and the Kaiser criterion) aren’t as good as the lesser-used parallel analysis approach. For a gentle introduction to the topic, check out <span class="citation"><a href="#ref-schmittCurrentMethodologicalConsiderations2011" role="doc-biblioref">Schmitt</a> (<a href="#ref-schmittCurrentMethodologicalConsiderations2011" role="doc-biblioref">2011</a>)</span>. Though we won’t make use of it, here, the <strong>psych</strong> package <span class="citation">(<a href="#ref-R-psych" role="doc-biblioref">Revelle, 2021</a>)</span> offers some nice options for parallel analysis by way of the <code>fa.parallel()</code> function.</p>
</div>
<div id="finally-we-fit-a-few-efas." class="section level3">
<h3>Finally, we fit a few EFAs.</h3>
<p>It’s time to fit our three EFAs. When defining the EFA models within <strong>lavaan</strong>, the critical features are how one defines the factors on the left-hand side of the equations. Here we define the models for all 65 items.</p>
<pre class="r"><code># 1-factor model
f1 &lt;- &#39;
efa(&quot;efa&quot;)*f1 =~ y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 +
                   y11 + y12 + y13 + y14 + y15 + y16 + y17 + y18 + y19 + y20 + 
                   y21 + y22 + y23 + y24 + y25 + y26 + y27 + y28 + y29 + y30 +
                   y31 + y32 + y33 + y34 + y35 + y36 + y37 + y38 + y39 + y40 +
                   y41 + y42 + y43 + y44 + y45 + y46 + y47 + y48 + y49 + y50 +
                   y51 + y52 + y53 + y54 + y55 + y56 + y57 + y58 + y59 + y60 +
                   y61 + y62 + y63 + y64 + y65
&#39;

# 2-factor model
f2 &lt;- &#39;
efa(&quot;efa&quot;)*f1 +
efa(&quot;efa&quot;)*f2 =~ y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 +
                   y11 + y12 + y13 + y14 + y15 + y16 + y17 + y18 + y19 + y20 + 
                   y21 + y22 + y23 + y24 + y25 + y26 + y27 + y28 + y29 + y30 +
                   y31 + y32 + y33 + y34 + y35 + y36 + y37 + y38 + y39 + y40 +
                   y41 + y42 + y43 + y44 + y45 + y46 + y47 + y48 + y49 + y50 +
                   y51 + y52 + y53 + y54 + y55 + y56 + y57 + y58 + y59 + y60 +
                   y61 + y62 + y63 + y64 + y65
&#39;

# 3-factor model
f3 &lt;- &#39;
efa(&quot;efa&quot;)*f1 +
efa(&quot;efa&quot;)*f2 +
efa(&quot;efa&quot;)*f3 =~ y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 +
                   y11 + y12 + y13 + y14 + y15 + y16 + y17 + y18 + y19 + y20 + 
                   y21 + y22 + y23 + y24 + y25 + y26 + y27 + y28 + y29 + y30 +
                   y31 + y32 + y33 + y34 + y35 + y36 + y37 + y38 + y39 + y40 +
                   y41 + y42 + y43 + y44 + y45 + y46 + y47 + y48 + y49 + y50 +
                   y51 + y52 + y53 + y54 + y55 + y56 + y57 + y58 + y59 + y60 +
                   y61 + y62 + y63 + y64 + y65
&#39;</code></pre>
<p>Now we’ve defined the three EFA models, we can fit the actual EFAs. One can currently do so with either the <code>cfa()</code> or <code>sem()</code> functions. The default rotation method is oblique Geomin. If you’re not up on rotation methods, you might check out <span class="citation"><a href="#ref-sass2010comparative" role="doc-biblioref">Sass &amp; Schmitt</a> (<a href="#ref-sass2010comparative" role="doc-biblioref">2010</a>)</span>. Here we’ll give a nod to tradition and use oblique Oblimin by setting <code>rotation = "oblimin"</code>. Also, note our use of <code>ordered = TRUE</code>, which explicitly tells <code>lavaan::cfa()</code> to treat all 65 of our items as ordinal.</p>
<pre class="r"><code>efa_f1 &lt;- 
  cfa(model = f1,
      data = d,
      rotation = &quot;oblimin&quot;,
      estimator = &quot;WLSMV&quot;,
      ordered = TRUE)

efa_f2 &lt;- 
  cfa(model = f2,
      data = d,
      rotation = &quot;oblimin&quot;,
      estimator = &quot;WLSMV&quot;,
      ordered = TRUE)

efa_f3 &lt;- 
  cfa(model = f3,
      data = d,
      rotation = &quot;oblimin&quot;,
      estimator = &quot;WLSMV&quot;,
      ordered = TRUE)</code></pre>
<p>For the sake of space, I’m not going to show the output, here. But if you want the verbose <strong>lavaan</strong>-style model summary for your EFA, you can use <code>summary()</code> function just the same way you would for a CFA.</p>
<pre class="r"><code>summary(efa_f1, fit.measures = TRUE)
summary(efa_f2, fit.measures = TRUE)
summary(efa_f3, fit.measures = TRUE)</code></pre>
<p>What we will focus on, though, is how one might compare the EFAs by some of their fit statistics.</p>
<pre class="r"><code># define the fit measures
fit_measures_robust &lt;- c(&quot;chisq.scaled&quot;, &quot;df&quot;, &quot;pvalue.scaled&quot;, 
                         &quot;cfi.scaled&quot;, &quot;rmsea.scaled&quot;, &quot;srmr&quot;)

# collect them for each model
rbind(
  fitmeasures(efa_f1, fit_measures_robust),
  fitmeasures(efa_f2, fit_measures_robust),
  fitmeasures(efa_f3, fit_measures_robust)) %&gt;% 
  # wrangle
  data.frame() %&gt;% 
  mutate(chisq.scaled  = round(chisq.scaled, digits = 0),
         df            = as.integer(df),
         pvalue.scaled = ifelse(pvalue.scaled == 0, &quot;&lt; .001&quot;, pvalue.scaled)) %&gt;% 
  mutate_at(vars(cfi.scaled:srmr), ~round(., digits =  3))</code></pre>
<pre><code>##   chisq.scaled   df pvalue.scaled cfi.scaled rmsea.scaled  srmr
## 1        20136 2015        &lt; .001      0.825         0.06 0.070
## 2        13946 1951        &lt; .001      0.884         0.05 0.054
## 3         9505 1888        &lt; .001      0.926         0.04 0.043</code></pre>
<p>As is often the case, the fit got steadily better with each added factor. Here’s how one might work with the output from the <code>standardizedsolution()</code> function to plot the <span class="math inline">\(\lambda\)</span>’s for the 3-factor solution.</p>
<pre class="r"><code># wrangle
standardizedsolution(efa_f3) %&gt;% 
  filter(op == &quot;=~&quot;) %&gt;% 
  mutate(item  = str_remove(rhs, &quot;y&quot;) %&gt;% as.double(),
         factor = str_remove(lhs, &quot;f&quot;)) %&gt;% 
  
  # plot
  ggplot(aes(x = est.std, xmin = ci.lower, xmax = ci.upper, y = item)) +
  annotate(geom = &quot;rect&quot;,
           xmin = -1, xmax = 1,
           ymin = -Inf, ymax = Inf,
           fill = &quot;grey90&quot;) +
  annotate(geom = &quot;rect&quot;,
           xmin = -0.7, xmax = 0.7,
           ymin = -Inf, ymax = Inf,
           fill = &quot;grey93&quot;) +
  annotate(geom = &quot;rect&quot;,
           xmin = -0.4, xmax = 0.4,
           ymin = -Inf, ymax = Inf,
           fill = &quot;grey96&quot;) +
  geom_vline(xintercept = 0, color = &quot;white&quot;) +
  geom_pointrange(aes(alpha = abs(est.std) &lt; 0.4),
                  fatten = 5) +
  geom_text(aes(label = item, color = abs(est.std) &lt; 0.4),
            size = 2) +
  scale_color_manual(values = c(&quot;white&quot;, &quot;transparent&quot;)) +
  scale_alpha_manual(values = c(1, 1/3)) +
  scale_x_continuous(expression(lambda[standardized]), 
                     expand = c(0, 0), limits = c(-1, 1),
                     breaks = c(-1, -0.7, -0.4, 0, 0.4, 0.7, 1),
                     labels = c(&quot;-1&quot;, &quot;-.7&quot;, &quot;-.4&quot;, &quot;0&quot;, &quot;.4&quot;, &quot;.7&quot;, &quot;1&quot;)) +
  scale_y_continuous(breaks = 1:65, sec.axis = sec_axis(~ . * 1, breaks = 1:65)) +
  ggtitle(&quot;EFICA-P loadings for the 3-factor model&quot;) +
  theme(legend.position = &quot;none&quot;) +
  facet_wrap(~ factor, labeller = label_both)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-12-1.png" width="624" /></p>
<p>To reduce visual complexity, <span class="math inline">\(\lambda\)</span>’s less than the conventional 0.4 threshold are semitransparent. Those above the threshold have the item number in the dot. I’m not going to offer an interpretation, here, since that’s not really the point of this post. But hopefully this will get you started fitting all the <strong>lavaan</strong>-based EFAs your heart desires.</p>
</div>
</div>
<div id="how-about-esem" class="section level2">
<h2>How about ESEM?</h2>
<p>If one can fit EFAs in <strong>lavaan</strong>, how about exploratory structural equation models <span class="citation">(ESEM, <a href="#ref-asparouhovESEM2009" role="doc-biblioref">Asparouhov &amp; Muthén, 2009</a>)</span>. Yes, I believe one can. To get a sense, check out my search results at <a href="https://github.com/yrosseel/lavaan/search?q=esem">https://github.com/yrosseel/lavaan/search?q=esem</a>. I haven’t had a reason to explore this for any of my projects, but it looks promising. If you master the <strong>lavaan</strong> ESEM method, maybe you could write a blot post of your own. Also, check out the blog post by <a href="https://twitter.com/MateusPsi">Mateus Silvestrin</a>, <a href="https://msilvestrin.me/post/esem/#ref-asparouhov_exploratory_2009"><em>Exploratory Structural Equation Modeling in R</em></a>.</p>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] lavaan_0.6-7    forcats_0.5.1   stringr_1.4.0   dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
##  [8] tibble_3.1.1    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.6          lubridate_1.7.9.2   assertthat_0.2.1    digest_0.6.27       utf8_1.2.1         
##  [6] R6_2.5.0            cellranger_1.1.0    backports_1.2.1     reprex_0.3.0        stats4_4.0.4       
## [11] evaluate_0.14       highr_0.9           httr_1.4.2          blogdown_1.3        pillar_1.6.0       
## [16] rlang_0.4.11        readxl_1.3.1        rstudioapi_0.13     jquerylib_0.1.4     pbivnorm_0.6.0     
## [21] rmarkdown_2.7       labeling_0.4.2      munsell_0.5.0       broom_0.7.5         numDeriv_2016.8-1.1
## [26] compiler_4.0.4      modelr_0.1.8        xfun_0.22           pkgconfig_2.0.3     mnormt_2.0.2       
## [31] tmvnsim_1.0-2       htmltools_0.5.1.1   tidyselect_1.1.0    bookdown_0.21       codetools_0.2-18   
## [36] fansi_0.4.2         viridisLite_0.4.0   crayon_1.4.1        dbplyr_2.0.0        withr_2.4.2        
## [41] grid_4.0.4          jsonlite_1.7.2      gtable_0.3.0        lifecycle_1.0.0     DBI_1.1.0          
## [46] magrittr_2.0.1      scales_1.1.1        cli_2.5.0           stringi_1.5.3       farver_2.1.0       
## [51] fs_1.5.0            xml2_1.3.2          bslib_0.2.4         ellipsis_0.3.2      generics_0.1.0     
## [56] vctrs_0.3.8         tools_4.0.4         glue_1.4.2          hms_0.5.3           yaml_2.2.1         
## [61] colorspace_2.0-0    rvest_0.3.6         knitr_1.33          haven_2.3.1         sass_0.3.1</code></pre>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-arrudaPsychometricProperties2020" class="csl-entry">
Arruda, M. A., Arruda, R., &amp; Anunciação, L. (2020). Psychometric properties and clinical utility of the executive function inventory for children and adolescents: A large multistage populational study including children with <span>ADHD</span>. <em>Applied Neuropsychology: Child</em>, 1–17. <a href="https://doi.org/10.1080/21622965.2020.1726353">https://doi.org/10.1080/21622965.2020.1726353</a>
</div>
<div id="ref-asparouhovESEM2009" class="csl-entry">
Asparouhov, T., &amp; Muthén, B. (2009). Exploratory structural equation modeling. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>16</em>(3), 397–438. <a href="https://doi.org/10.1080/10705510903008204">https://doi.org/10.1080/10705510903008204</a>
</div>
<div id="ref-flora2004empirical" class="csl-entry">
Flora, D. B., &amp; Curran, P. J. (2004). An empirical evaluation of alternative methods of estimation for confirmatory factor analysis with ordinal data. <em>Psychological Methods</em>, <em>9</em>(4), 466. <a href="https://doi.org/10.1037/1082-989X.9.4.466">https://doi.org/10.1037/1082-989X.9.4.466</a>
</div>
<div id="ref-liCFAWithOrdinalData2016" class="csl-entry">
Li, C.-H. (2016). Confirmatory factor analysis with ordinal data: <span>Comparing</span> robust maximum likelihood and diagonally weighted least squares. <em>Behavior Research Methods</em>, <em>48</em>(3), 936–949. <a href="https://doi.org/10.3758/s13428-015-0619-7">https://doi.org/10.3758/s13428-015-0619-7</a>
</div>
<div id="ref-R-psych" class="csl-entry">
Revelle, W. (2021). <em><span class="nocase">psych</span>: <span>Procedures</span> for psychological, psychometric, and personality research</em>. <a href="https://CRAN.R-project.org/package=psych">https://CRAN.R-project.org/package=psych</a>
</div>
<div id="ref-rosseellavaan2012" class="csl-entry">
Rosseel, Y. (2012). <span class="nocase">lavaan</span>: <span>An R</span> package for structural equation modeling. <em>Journal of Statistical Software</em>, <em>48</em>(2), 1–36. <a href="https://doi.org/10.18637/jss.v048.i02">https://doi.org/10.18637/jss.v048.i02</a>
</div>
<div id="ref-R-lavaan" class="csl-entry">
Rosseel, Y., &amp; Jorgensen, T. D. (2019). <em><span class="nocase">lavaan</span>: <span>Latent</span> variable analysis</em> [Manual]. <a href="https://lavaan.org">https://lavaan.org</a>
</div>
<div id="ref-sass2010comparative" class="csl-entry">
Sass, D. A., &amp; Schmitt, T. A. (2010). A comparative investigation of rotation criteria within exploratory factor analysis. <em>Multivariate Behavioral Research</em>, <em>45</em>(1), 73–103. <a href="https://doi.org/10.1080/00273170903504810">https://doi.org/10.1080/00273170903504810</a>
</div>
<div id="ref-schmittCurrentMethodologicalConsiderations2011" class="csl-entry">
Schmitt, T. A. (2011). Current methodological considerations in exploratory and confirmatory factor analysis. <em>Journal of Psychoeducational Assessment</em>, <em>29</em>(4), 304–321. <a href="https://doi.org/10.1177/0734282911406653">https://doi.org/10.1177/0734282911406653</a>
</div>
</div>
</div>
